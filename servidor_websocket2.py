import asyncio
import websockets
import json
import os
import base64
import tempfile
from gtts import gTTS

# Importaciones para LangChain y Ollama
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import aiohttp

# Base de conocimiento - documentaci√≥n t√©cnica de sistemas de refrigeraci√≥n industrial
BASE_CONOCIMIENTO = [
    {
        "id": "DOC001",
        "titulo": "Manual de sensores de temperatura para sistemas de refrigeraci√≥n industrial",
        "descripcion": "Gu√≠a completa de selecci√≥n, instalaci√≥n y mantenimiento de sensores de temperatura.",
        "url": "https://www.ejemplo.com/manuales/sensores-temperatura.pdf",
        "keywords": ["sensor", "temperatura", "termostato", "RTD", "termopar", "PT100", "-50", "calibraci√≥n"]
    },
    {
        "id": "DOC002",
        "titulo": "Procedimiento de mantenimiento de evaporadores industriales",
        "descripcion": "Protocolo para inspecci√≥n, limpieza y mantenimiento preventivo de evaporadores.",
        "url": "https://www.ejemplo.com/procedimientos/mantenimiento-evaporadores.pdf",
        "keywords": ["evaporador", "escarcha", "hielo", "deshielo", "ventilador", "aletas", "serpent√≠n"]
    },
    {
        "id": "DOC003",
        "titulo": "Gu√≠a de diagn√≥stico de fallos en compresores",
        "descripcion": "Identificaci√≥n y resoluci√≥n de problemas comunes en compresores industriales.",
        "url": "https://www.ejemplo.com/guias/diagnostico-compresores.pdf",
        "keywords": ["compresor", "bitzer", "vibraci√≥n", "ruido", "presi√≥n", "aceite", "sobrecalentamiento"]
    },
    {
        "id": "DOC004",
        "titulo": "Configuraci√≥n de protocolos MQTT para monitorizaci√≥n IIoT",
        "descripcion": "Implementaci√≥n de comunicaci√≥n MQTT en sistemas de refrigeraci√≥n industrial.",
        "url": "https://www.ejemplo.com/configuracion/mqtt-refrigeracion.pdf",
        "keywords": ["MQTT", "protocolo", "comunicaci√≥n", "broker", "t√≥pico", "suscripci√≥n", "publicaci√≥n"]
    },
    {
        "id": "DOC005",
        "titulo": "Est√°ndares HACCP para cadenas de fr√≠o",
        "descripcion": "Implementaci√≥n de HACCP en procesos de refrigeraci√≥n industrial para alimentos.",
        "url": "https://www.ejemplo.com/normativas/haccp-refrigeracion.pdf",
        "keywords": ["HACCP", "cadena de fr√≠o", "seguridad alimentaria", "punto cr√≠tico", "monitoreo", "temperatura", "registro"]
    },
    {
        "id": "DOC006",
        "titulo": "Optimizaci√≥n de eficiencia energ√©tica en condensadores",
        "descripcion": "M√©todos para reducir el consumo energ√©tico en sistemas de condensaci√≥n.",
        "url": "https://www.ejemplo.com/eficiencia/condensadores.pdf",
        "keywords": ["condensador", "eficiencia", "energ√≠a", "consumo", "kW", "ventilador", "presi√≥n", "subenfriamiento"]
    },
    {
        "id": "DOC007",
        "titulo": "Implementaci√≥n de sistemas SCADA para refrigeraci√≥n industrial",
        "descripcion": "Gu√≠a para integraci√≥n de sistemas SCADA en plantas de refrigeraci√≥n.",
        "url": "https://www.ejemplo.com/sistemas/scada-refrigeracion.pdf",
        "keywords": ["SCADA", "HMI", "monitoreo", "control", "automatizaci√≥n", "supervisi√≥n", "alarma"]
    },
    {
        "id": "DOC008",
        "titulo": "Gu√≠a de refrigerantes industriales",
        "descripcion": "Propiedades, aplicaciones y manejo seguro de refrigerantes industriales.",
        "url": "https://www.ejemplo.com/guias/refrigerantes.pdf",
        "keywords": ["refrigerante", "amoniaco", "fre√≥n", "R404A", "R717", "carga", "presi√≥n", "temperatura"]
    },
    {
        "id": "DOC009",
        "titulo": "Manual de v√°lvulas de expansi√≥n",
        "descripcion": "Selecci√≥n, instalaci√≥n y diagn√≥stico de v√°lvulas de expansi√≥n.",
        "url": "https://www.ejemplo.com/manuales/valvulas-expansion.pdf",
        "keywords": ["v√°lvula", "expansi√≥n", "termost√°tica", "electr√≥nica", "sobrecalentamiento", "subenfriamiento"]
    },
    {
        "id": "DOC010",
        "titulo": "Procedimientos de emergencia ante fugas de refrigerante",
        "descripcion": "Protocolos de seguridad ante fugas de refrigerantes industriales.",
        "url": "https://www.ejemplo.com/seguridad/fugas-refrigerante.pdf",
        "keywords": ["fuga", "emergencia", "seguridad", "detector", "evacuaci√≥n", "protecci√≥n", "amoniaco"]
    }
]

def buscar_documentos_relevantes(texto, max_docs=3):
    """Busca documentos relevantes basados en palabras clave en el texto"""
    # Convertir texto a min√∫sculas para b√∫squeda insensible a may√∫sculas
    texto_lower = texto.lower()
    
    # Calcular relevancia para cada documento
    docs_relevancia = []
    for doc in BASE_CONOCIMIENTO:
        relevancia = 0
        for keyword in doc["keywords"]:
            if keyword.lower() in texto_lower:
                relevancia += 1
                
        if relevancia > 0:
            docs_relevancia.append({
                "documento": doc,
                "relevancia": relevancia
            })
    
    # Ordenar por relevancia y limitar al n√∫mero m√°ximo
    docs_relevancia.sort(key=lambda x: x["relevancia"], reverse=True)
    docs_seleccionados = [item["documento"] for item in docs_relevancia[:max_docs]]
    
    return docs_seleccionados

class AsyncOllama:
    """Clase para manejar llamadas as√≠ncronas a Ollama"""
    def __init__(self, model_name="gemma3", base_url="http://localhost:11434"):
        self.model_name = model_name
        self.base_url = base_url
        
    async def generate(self, prompt):
        """Genera una respuesta usando Ollama API de forma as√≠ncrona"""
        async with aiohttp.ClientSession() as session:
            url = f"{self.base_url}/api/generate"
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False
            }
            
            try:
                async with session.post(url, json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get("response", "")
                    else:
                        error = await response.text()
                        print(f"Error de Ollama: {error}")
                        return f"Error al procesar tu consulta. Por favor, intenta de nuevo m√°s tarde."
            except Exception as e:
                print(f"Error de conexi√≥n con Ollama: {e}")
                return f"No se pudo conectar con el modelo de IA. Aseg√∫rate de que Ollama est√° ejecut√°ndose con el modelo gemma3."

async def procesar_con_langchain(texto):
    """Procesa el texto usando LangChain y Ollama con un prompt especializado en IIoT para refrigeraci√≥n"""
    try:
        # Definir el PromptTemplate para sistemas IIoT de refrigeraci√≥n industrial
        template = """
        # INSTRUCCIONES PARA EL ASISTENTE DE SOPORTE T√âCNICO DE SISTEMAS IIOT DE REFRIGERACI√ìN INDUSTRIAL
        
        Eres FR√çO-BOT, un asistente virtual especializado en sistemas IIoT (Internet Industrial de las Cosas) para la monitorizaci√≥n y mantenimiento de cadenas de fr√≠o en refrigeraci√≥n industrial. Tu prop√≥sito es proporcionar soporte t√©cnico preciso, profesional y efectivo a t√©cnicos, operadores e ingenieros que trabajan con estos sistemas.
        
        ## TU CONOCIMIENTO ESPECIALIZADO INCLUYE:
        - Sensores de temperatura, humedad y presi√≥n en sistemas de refrigeraci√≥n industrial
        - Protocolos de comunicaci√≥n industrial: Modbus, OPC-UA, MQTT, BACnet
        - Sistemas SCADA y plataformas de monitoreo para cadenas de fr√≠o
        - Normativas HACCP, ISO 22000 y regulaciones sobre cadenas de fr√≠o
        - An√°lisis de datos, tendencias y predicci√≥n de fallos en compresores, evaporadores y condensadores
        - Mantenimiento preventivo y correctivo de sistemas de refrigeraci√≥n
        - Alertas y notificaciones en caso de desviaciones de temperatura
        - Eficiencia energ√©tica en sistemas de refrigeraci√≥n industrial
        
        ## CUANDO RESPONDAS:
        1. Analiza si la consulta est√° relacionada con: diagn√≥stico de problemas, configuraci√≥n de equipos, interpretaci√≥n de datos, mantenimiento preventivo o normativas.
        2. Usa terminolog√≠a t√©cnica adecuada para profesionales del sector.
        3. Prioriza la seguridad del sistema y la preservaci√≥n de la cadena de fr√≠o.
        4. S√© conciso pero completo, respetando los protocolos industriales.
        5. Cuando sea apropiado, pregunta por datos espec√≠ficos como: lecturas de sensores, modelos de equipos o registros de alarmas.
        6. Incluye referencias a posibles par√°metros cr√≠ticos que deben verificarse.
        7. No debes usar formato markdown
        
        ## CONSULTA DEL USUARIO:
        {input}
        
        ## RESPUESTA T√âCNICA:
        """
        
        prompt = PromptTemplate(template=template, input_variables=["input"])
        
        # Instanciar el cliente Ollama as√≠ncrono
        ollama_async = AsyncOllama(model_name="gemma3")
        
        # Preparar el prompt completo
        prompt_final = prompt.format(input=texto)
        
        # Generar respuesta del modelo
        respuesta = await ollama_async.generate(prompt_final)
        
        return respuesta.strip()
    except Exception as e:
        print(f"Error procesando con LangChain: {e}")
        return f"Lo siento, hubo un error al procesar tu consulta t√©cnica: {str(e)}"

async def generar_audio(texto, voz="es"):
    """Genera audio a partir de texto usando Google Text-to-Speech"""
    try:
        # Crear un archivo temporal para guardar el audio
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
            temp_path = temp_file.name
        
        # Generar el audio usando gTTS
        tts = gTTS(text=texto, lang=voz)
        tts.save(temp_path)
        
        # Leer el archivo de audio generado
        with open(temp_path, "rb") as audio_file:
            audio_data = audio_file.read()
        
        # Eliminar el archivo temporal
        os.remove(temp_path)
        
        # Convertir a base64 para enviar por WebSocket
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        return {
            "success": True,
            "audio_base64": audio_base64,
            "formato": "mp3"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

async def responder(websocket):
    """Maneja la conexi√≥n WebSocket"""
    print(f"üü¢ Cliente conectado desde {websocket.remote_address}")
    try:
        async for message in websocket:
            print(f"üì• Mensaje recibido: {message}")
            # Procesar JSON
            try:
                datos = json.loads(message)
                texto = datos.get("texto", "")
                voz = datos.get("voz", "es")
                use_ai = datos.get("use_ai", True)  # Opci√≥n para usar o no la IA
                
                if not texto:
                    respuesta = {"error": "No se proporcion√≥ texto para procesar"}
                    await websocket.send(json.dumps(respuesta))
                    continue
                
                # Buscar documentos relevantes en la base de conocimiento
                documentos_relevantes = buscar_documentos_relevantes(texto)
                
                # Procesar con IA si est√° habilitado
                texto_procesado = texto
                if use_ai:
                    print(f"üß† Procesando consulta t√©cnica con IA: {texto}")
                    texto_procesado = await procesar_con_langchain(texto)
                    print(f"üß† Respuesta t√©cnica de IA: {texto_procesado}")
                
                # Generar audio con el texto procesado
                resultado_audio = await generar_audio(texto_procesado, voz)
                respuesta = {
                    "tipo": "tts_respuesta",
                    "texto_original": texto,
                    "texto_procesado": texto_procesado,
                    "documentos": documentos_relevantes,  # Agregar documentos relevantes a la respuesta
                    **resultado_audio
                }
                
                await websocket.send(json.dumps(respuesta))
                print(f"üì§ Respuesta enviada: {'Audio generado correctamente' if respuesta.get('success', False) else respuesta}")
                
                if documentos_relevantes:
                    print(f"üìö Documentos relevantes encontrados: {len(documentos_relevantes)}")
                    for doc in documentos_relevantes:
                        print(f"   - {doc['titulo']}")
            
            except json.JSONDecodeError:
                respuesta = {"error": "JSON inv√°lido"}
                await websocket.send(json.dumps(respuesta))
            
    except websockets.exceptions.ConnectionClosed as e:
        print(f"üî¥ Cliente desconectado ({e.code}): {e.reason}")

async def main():
    """Inicia el servidor WebSocket."""
    print("üîä Asistente IIoT de Refrigeraci√≥n Industrial - Servidor iniciado")
    print("üßä FR√çO-BOT: Sistema de soporte t√©cnico para cadenas de fr√≠o")
    print("üìö Base de conocimiento cargada con", len(BASE_CONOCIMIENTO), "documentos")
    print("üöÄ Ejecut√°ndose en ws://localhost:8000")
    
    # Comprobar que Ollama est√° disponible
    try:
        ollama = AsyncOllama()
        test_response = await ollama.generate("Prueba de conexi√≥n")
        print(f"‚úÖ Ollama est√° funcionando correctamente")
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo conectar con Ollama: {e}")
        print("‚ö†Ô∏è Aseg√∫rate de que Ollama est√° instalado y ejecut√°ndose")
        print("‚ö†Ô∏è Tambi√©n verifica que el modelo 'gemma3' est√° disponible en Ollama")
        print("‚ö†Ô∏è Puedes instalarlo con: ollama pull gemma3")
        print("‚ö†Ô∏è El servidor continuar√°, pero las funciones de IA no funcionar√°n")
    
    # Utilizando la API actualizada de websockets
    async with websockets.serve(responder, "localhost", 8000):
        await asyncio.Future()  # Mantener el servidor activo indefinidamente

if __name__ == "__main__":
    asyncio.run(main())